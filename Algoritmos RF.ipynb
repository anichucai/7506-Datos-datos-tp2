{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de features elegidos con DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>K_storm</th>\n",
       "      <th>K_bomb</th>\n",
       "      <th>K_typhoon</th>\n",
       "      <th>K_wildfire</th>\n",
       "      <th>K_fire</th>\n",
       "      <th>K_derailment</th>\n",
       "      <th>K_suicide bomb</th>\n",
       "      <th>K_outbreak</th>\n",
       "      <th>K_earthquake</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_street</th>\n",
       "      <th>tag_plan</th>\n",
       "      <th>tag_charged</th>\n",
       "      <th>tag_photo_y</th>\n",
       "      <th>tag_bad</th>\n",
       "      <th>tag_level</th>\n",
       "      <th>tag_guy</th>\n",
       "      <th>tag_hail</th>\n",
       "      <th>tag_flooding</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  K_storm  K_bomb  K_typhoon  K_wildfire  K_fire  K_derailment  \\\n",
       "0   1        0       0          0           0       0             0   \n",
       "1   4        0       0          0           0       1             0   \n",
       "2   5        0       0          0           0       0             0   \n",
       "3   6        0       0          0           1       1             0   \n",
       "4   7        0       0          0           1       1             0   \n",
       "\n",
       "   K_suicide bomb  K_outbreak  K_earthquake  ...  tag_street  tag_plan  \\\n",
       "0               0           0             1  ...         0.0       0.0   \n",
       "1               0           0             0  ...         0.0       0.0   \n",
       "2               0           0             0  ...         0.0       0.0   \n",
       "3               0           0             0  ...         0.0       0.0   \n",
       "4               0           0             0  ...         0.0       0.0   \n",
       "\n",
       "   tag_charged  tag_photo_y  tag_bad  tag_level  tag_guy  tag_hail  \\\n",
       "0          0.0     0.000000      0.0        0.0      0.0       0.0   \n",
       "1          0.0     0.000000      0.0        0.0      0.0       0.0   \n",
       "2          0.0     0.000000      0.0        0.0      0.0       0.0   \n",
       "3          0.0     0.000000      0.0        0.0      0.0       0.0   \n",
       "4          0.0     0.570573      0.0        0.0      0.0       0.0   \n",
       "\n",
       "   tag_flooding  target  \n",
       "0           0.0       1  \n",
       "1           0.0       1  \n",
       "2           0.0       1  \n",
       "3           0.0       1  \n",
       "4           0.0       1  \n",
       "\n",
       "[5 rows x 395 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.read_csv('features/feature_selection/features_by_random_forest.csv').drop(columns=['Unnamed: 0'])\n",
    "train = pd.read_csv(\"original_data/train.csv\", dtype = {\"target\": int}, encoding='UTF_8')\n",
    "train = train[['id','target']]\n",
    "train_features = train_features.merge(train, on='id')\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('feature_selection_on_test_RF').drop(columns='Unnamed: 0').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>K_storm</th>\n",
       "      <th>K_bomb</th>\n",
       "      <th>K_typhoon</th>\n",
       "      <th>K_wildfire</th>\n",
       "      <th>K_fire</th>\n",
       "      <th>K_derailment</th>\n",
       "      <th>K_suicide bomb</th>\n",
       "      <th>K_outbreak</th>\n",
       "      <th>K_earthquake</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_love</th>\n",
       "      <th>tag_street</th>\n",
       "      <th>tag_plan</th>\n",
       "      <th>tag_charged</th>\n",
       "      <th>tag_photo_y</th>\n",
       "      <th>tag_bad</th>\n",
       "      <th>tag_level</th>\n",
       "      <th>tag_guy</th>\n",
       "      <th>tag_hail</th>\n",
       "      <th>tag_flooding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  K_storm  K_bomb  K_typhoon  K_wildfire  K_fire  K_derailment  \\\n",
       "0   0        0       0          0           0       0             0   \n",
       "1   2        0       0          0           0       0             0   \n",
       "2   3        0       0          0           0       1             0   \n",
       "3   9        0       0          0           1       1             0   \n",
       "4  11        0       0          1           0       0             0   \n",
       "\n",
       "   K_suicide bomb  K_outbreak  K_earthquake  ...  tag_love  tag_street  \\\n",
       "0               0           0             0  ...       0.0     0.00000   \n",
       "1               0           0             1  ...       0.0     0.00000   \n",
       "2               0           0             0  ...       0.0     0.74681   \n",
       "3               0           0             0  ...       0.0     0.00000   \n",
       "4               0           0             0  ...       0.0     0.00000   \n",
       "\n",
       "   tag_plan  tag_charged  tag_photo_y  tag_bad  tag_level  tag_guy  tag_hail  \\\n",
       "0       0.0          0.0          0.0      0.0        0.0      0.0       0.0   \n",
       "1       0.0          0.0          0.0      0.0        0.0      0.0       0.0   \n",
       "2       0.0          0.0          0.0      0.0        0.0      0.0       0.0   \n",
       "3       0.0          0.0          0.0      0.0        0.0      0.0       0.0   \n",
       "4       0.0          0.0          0.0      0.0        0.0      0.0       0.0   \n",
       "\n",
       "   tag_flooding  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "\n",
       "[5 rows x 374 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_accuracy(modelo,x_train,y_train,x_test,y_test):\n",
    "    with open(\"prediction_history.csv\", \"a\") as myfile:\n",
    "        predicted = modelo.predict(x_train)\n",
    "        train_prediction = str(metrics.accuracy_score(y_train,predicted))\n",
    "        print('Score para x_train: '+ train_prediction)\n",
    "        predicted = modelo.predict(x_test)\n",
    "        test_prediction = str(metrics.accuracy_score(y_test,predicted))\n",
    "        print('Score para x_test: '+ test_prediction)\n",
    "        params = str(modelo)\n",
    "        print('Hiperparametros: '+ str(modelo))\n",
    "        myfile.write(params+','+test_prediction+\",\"+train_prediction+\",\"+str(datetime.datetime.now())+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(model, test, name):\n",
    "    df_prediccion = test[['id']].copy()\n",
    "    predicted = model.predict(test.drop(columns='id'))\n",
    "    df_prediccion['target'] = predicted\n",
    "    df_prediccion.to_csv('predictions/'+name+str(datetime.datetime.now())+'.csv', index=None)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_features.drop(columns = ['target'])\n",
    "train_df = train_df.fillna(0)\n",
    "\n",
    "#Split the CountVector vectorized data into train and test datasets for model training and testing\n",
    "X_train, X_test, y_train, y_test =train_test_split(train_df,train_features.target,test_size=0.2,random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación de accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aca hay mas cosas interesantes https://www.ritchieng.com/machine-learning-evaluate-classification-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    #errors = abs(predictions - test_labels)\n",
    "    #mape = 100 * np.mean(errors / test_labels)\n",
    "    #accuracy = 100 - mape\n",
    "    accuracy = round(accuracy_score(test_labels,predictions)*100)\n",
    "    print('Model Performance')\n",
    "    #print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(model,X_train,y_train,X_test,y_test):    \n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions=clf.predict(X_test)\n",
    "    confusion_matrix(y_test,predictions)\n",
    "    conf = metrics.confusion_matrix(y_test, predictions)\n",
    "    conf = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]\n",
    "    print_cm(conf, ['true','false'])\n",
    "    print('-'*50)\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print('-'*50)\n",
    "    print(\"{}\" .format(model))\n",
    "    print('-'*50)\n",
    "    print('Accuracy of classifier on training set:{}%'.format(round(clf.score(X_train, y_train)*100)))\n",
    "    print('-'*50)\n",
    "    print('Accuracy of classifier on test set:{}%' .format(round(accuracy_score(y_test,predictions)*100)))\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[LogisticRegression(C=1.0,max_iter=5000),SVC(),MultinomialNB(),DecisionTreeClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors=5),RandomForestClassifier(),GaussianNB(),SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(columns='id')\n",
    "X_train = X_train.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           true false \n",
      "     true   0.8   0.2 \n",
      "    false   0.4   0.6 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78       849\n",
      "           1       0.75      0.58      0.66       674\n",
      "\n",
      "    accuracy                           0.73      1523\n",
      "   macro avg       0.73      0.71      0.72      1523\n",
      "weighted avg       0.73      0.73      0.72      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:77%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:73%\n",
      "**************************************************\n",
      "           true false \n",
      "     true   0.8   0.2 \n",
      "    false   0.6   0.4 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73       849\n",
      "           1       0.67      0.42      0.52       674\n",
      "\n",
      "    accuracy                           0.65      1523\n",
      "   macro avg       0.66      0.63      0.62      1523\n",
      "weighted avg       0.66      0.65      0.63      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:66%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:65%\n",
      "**************************************************\n",
      "           true false \n",
      "     true   0.8   0.2 \n",
      "    false   0.5   0.5 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76       849\n",
      "           1       0.72      0.53      0.61       674\n",
      "\n",
      "    accuracy                           0.70      1523\n",
      "   macro avg       0.71      0.68      0.68      1523\n",
      "weighted avg       0.70      0.70      0.69      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:72%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:70%\n",
      "**************************************************\n",
      "           true false \n",
      "     true   0.7   0.3 \n",
      "    false   0.4   0.6 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       849\n",
      "           1       0.66      0.64      0.65       674\n",
      "\n",
      "    accuracy                           0.70      1523\n",
      "   macro avg       0.69      0.69      0.69      1523\n",
      "weighted avg       0.69      0.70      0.69      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:99%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:70%\n",
      "**************************************************\n",
      "           true false \n",
      "     true   0.8   0.2 \n",
      "    false   0.5   0.5 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72       849\n",
      "           1       0.65      0.48      0.55       674\n",
      "\n",
      "    accuracy                           0.66      1523\n",
      "   macro avg       0.66      0.64      0.64      1523\n",
      "weighted avg       0.66      0.66      0.65      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:77%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:66%\n",
      "**************************************************\n",
      "           true false \n",
      "     true   0.9   0.1 \n",
      "    false   0.4   0.6 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.81       849\n",
      "           1       0.80      0.62      0.70       674\n",
      "\n",
      "    accuracy                           0.76      1523\n",
      "   macro avg       0.77      0.75      0.75      1523\n",
      "weighted avg       0.77      0.76      0.76      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:99%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:76%\n",
      "**************************************************\n",
      "           true false \n",
      "     true   1.0   0.0 \n",
      "    false   0.6   0.4 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.78       849\n",
      "           1       0.89      0.36      0.51       674\n",
      "\n",
      "    accuracy                           0.70      1523\n",
      "   macro avg       0.77      0.66      0.65      1523\n",
      "weighted avg       0.76      0.70      0.66      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:71%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:70%\n",
      "**************************************************\n",
      "           true false \n",
      "     true   0.9   0.1 \n",
      "    false   0.6   0.4 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.78       849\n",
      "           1       0.82      0.43      0.57       674\n",
      "\n",
      "    accuracy                           0.71      1523\n",
      "   macro avg       0.75      0.68      0.67      1523\n",
      "weighted avg       0.74      0.71      0.68      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:73%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:71%\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    fit_and_predict(model,X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación de accuracy con Cross-Validation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_cross_val(model,X_train,y_train,X_test,y_test):\n",
    "    print(\"{}\" .format(model))\n",
    "    print('-'*50)\n",
    "    print('Accuracy of classifier on training set:{}%'.format(round(cross_val_score(model, X_train, y_train, scoring='accuracy', cv = 10).mean()*100)))\n",
    "    print('-'*50)\n",
    "    print('Accuracy of classifier on test set:{}%' .format(round(cross_val_score(model, X_test, y_test, scoring='accuracy', cv = 10).mean()*100)))\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:75%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:73%\n",
      "**************************************************\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:65%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:62%\n",
      "**************************************************\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:71%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:68%\n",
      "**************************************************\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:68%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:62%\n",
      "**************************************************\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:65%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:62%\n",
      "**************************************************\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:75%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:72%\n",
      "**************************************************\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:70%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:69%\n",
      "**************************************************\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:62%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:62%\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    fit_and_predict_cross_val(model,X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['entropy', 'gini'], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [1.0, 23.11111111111111, 45.22222222222222, 67.33333333333333, 89.44444444444444, 111.55555555555556, 133.66666666666666, 155.77777777777777, 177.88888888888889, 200.0, None], 'min_samples_split': array([0.        , 0.44444444, 0.88888889, 1.33333333, 1.77777778,\n",
      "       2.22222222, 2.66666667, 3.11111111, 3.55555556, 4.        ]), 'min_samples_leaf': array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45]), 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV # Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = list(np.linspace(1, 200, 10, endpoint=True))\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = np.linspace(0.0, 4.0, 10, endpoint=True)\n",
    "                              \n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = np.arange(0.0, 0.5,0.05)\n",
    "                              \n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "                              \n",
    "random_grid = {\"criterion\": [\"entropy\",\"gini\"],\n",
    "                'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   30.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                                        'min_samples_leaf': array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45]),\n",
       "                                        'min_samples_split': array([0.        , 0.44444444, 0.88888889, 1.33333333, 1.77777778,\n",
       "       2.22222222, 2.66666667, 3.11111111, 3.55555556, 4.        ]),\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42,n_jobs=-1)# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 200.0,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 0.15000000000000002,\n",
       " 'min_samples_split': 0.8888888888888888,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 72.00%.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 62.00%.\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of -13.89%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=200.0, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=0.15000000000000002,\n",
       "                       min_samples_split=0.8888888888888888,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para x_train: 0.625615763546798\n",
      "Score para x_test: 0.6152330925804333\n",
      "Hiperparametros: RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=200.0, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=0.15000000000000002,\n",
      "                       min_samples_split=0.8888888888888888,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "save_prediction_accuracy(best_random, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb #conda install -c conda-forge lightgbm\n",
    "\n",
    "params_LG = {'objective':['binary'],\n",
    "                             'learning_rate':[0.005,0.01,0.05,0.1,0.3],\n",
    "                             'n_estimators':np.arange(25,200,15),\n",
    "                             'num_leaves': np.arange(24, 45,3),\n",
    "                             'feature_fraction': np.arange(0.1, 0.91, 0.2),   \n",
    "                             'bagging_fraction': np.arange(0.8, 1.01, 0.1),\n",
    "                             'max_depth': np.arange(3, 12, 1),\n",
    "                            #{'lambda_l1': np.arange(0, 5)}, # Restaba mucho\n",
    "                             'lambda_l2': np.arange(0, 3),\n",
    "                             'min_split_gain': [0.001, 0.01, 0.1],\n",
    "                             'min_child_weight': [1e-05]+np.arange(5, 11)}\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leaves=31, objective=None,\n",
       "                                            random_state=None, reg_alpha=0.0,\n",
       "                                            reg_lambda=0.0, sile...\n",
       "                                        'max_depth': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11]),\n",
       "                                        'min_child_weight': array([ 5.00001,  6.00001,  7.00001,  8.00001,  9.00001, 10.00001]),\n",
       "                                        'min_split_gain': [0.001, 0.01, 0.1],\n",
       "                                        'n_estimators': array([ 25,  40,  55,  70,  85, 100, 115, 130, 145, 160, 175, 190]),\n",
       "                                        'num_leaves': array([24, 27, 30, 33, 36, 39, 42]),\n",
       "                                        'objective': ['binary']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = lgb.LGBMClassifier()\n",
    "rf_LG = RandomizedSearchCV(estimator = rf, param_distributions = params_LG, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs=-1)# Fit the random search model\n",
    "rf_LG.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.8,\n",
       " 'feature_fraction': 0.7000000000000001,\n",
       " 'lambda_l2': 1,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 6.00001,\n",
       " 'min_split_gain': 0.01,\n",
       " 'n_estimators': 100,\n",
       " 'num_leaves': 27,\n",
       " 'objective': 'binary'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_LG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 72.00%.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 75.00%.\n"
     ]
    }
   ],
   "source": [
    "best_LG = rf_LG.best_estimator_\n",
    "random_accuracy = evaluate(best_LG, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 4.17%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para x_train: 0.819047619047619\n",
      "Score para x_test: 0.7485226526592252\n",
      "Hiperparametros: LGBMClassifier(bagging_fraction=0.8, boosting_type='gbdt', class_weight=None,\n",
      "               colsample_bytree=1.0, feature_fraction=0.7000000000000001,\n",
      "               importance_type='split', lambda_l2=1, learning_rate=0.1,\n",
      "               max_depth=10, min_child_samples=20, min_child_weight=6.00001,\n",
      "               min_split_gain=0.01, n_estimators=100, n_jobs=-1, num_leaves=27,\n",
      "               objective='binary', random_state=None, reg_alpha=0.0,\n",
      "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "save_prediction_accuracy(best_LG, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURONAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "params_MLPC = {'hidden_layer_sizes':[(n,n) for n in range(1,30)],\n",
    "                              'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "                              'alpha':[1e-06,1e-05,1e-04,1e-03,1e-02,1e-01,1],\n",
    "                              'beta_1':np.arange(0.0,1,0.01),\n",
    "                              'beta_2':np.arange(0.0,1,0.01),\n",
    "                              'early_stopping':[True, False],\n",
    "                              'epsilon':[1e-07,1e-08,1e-06, 1e-09, 1e-010, 1e-11],\n",
    "                              'learning_rate':['constant', 'adaptive'],\n",
    "                              'solver':['adam', 'lbfgs', 'sgd'],\n",
    "                              'validation_fraction':np.arange(0.15,0.5,0.01),\n",
    "                               'max_iter':[200,300,400],\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.4min finished\n",
      "/home/anichu/Programs/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                           batch_size='auto', beta_1=0.9,\n",
       "                                           beta_2=0.999, early_stopping=False,\n",
       "                                           epsilon=1e-08,\n",
       "                                           hidden_layer_sizes=(100,),\n",
       "                                           learning_rate='constant',\n",
       "                                           learning_rate_init=0.001,\n",
       "                                           max_fun=15000, max_iter=200,\n",
       "                                           momentum=0.9, n_iter_no_change=10,\n",
       "                                           nesterovs_momentum=True, power_t=0.5,\n",
       "                                           random...\n",
       "                                        'max_iter': [200, 300, 400],\n",
       "                                        'solver': ['adam', 'lbfgs', 'sgd'],\n",
       "                                        'validation_fraction': array([0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22, 0.23, 0.24, 0.25,\n",
       "       0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33, 0.34, 0.35, 0.36,\n",
       "       0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n",
       "       0.48, 0.49])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = MLPClassifier()\n",
    "rf_MLP = RandomizedSearchCV(estimator = rf, param_distributions = params_MLPC, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs=-1)# Fit the random search model\n",
    "rf_MLP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'alpha': 1e-06,\n",
       " 'beta_1': 0.98,\n",
       " 'beta_2': 0.8200000000000001,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-10,\n",
       " 'hidden_layer_sizes': (6, 6),\n",
       " 'learning_rate': 'constant',\n",
       " 'max_iter': 400,\n",
       " 'solver': 'lbfgs',\n",
       " 'validation_fraction': 0.18000000000000002}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_MLP.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 72.00%.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 62.00%.\n"
     ]
    }
   ],
   "source": [
    "best_MLP = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_MLP, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of -13.89%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para x_train: 0.625615763546798\n",
      "Score para x_test: 0.6152330925804333\n",
      "Hiperparametros: RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=200.0, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=0.15000000000000002,\n",
      "                       min_samples_split=0.8888888888888888,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "save_prediction_accuracy(best_MLP, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC \n",
    "params_GBC = {\n",
    "    'max_features':['auto', 'sqrt', 'log2'],\n",
    "                             'max_leaf_nodes': [None,1,2,3,4,5,6,8],\n",
    "                             'min_weight_fraction_leaf': np.linspace(0.0, 0.5, 1, endpoint=True),\n",
    "                             'learning_rate': np.arange(0.1, 0.5, 0.05),\n",
    "                             'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "                             'min_samples_leaf': np.arange(0.1, 0.5, 5),  \n",
    "                             'max_features' : list(range(1,100)),\n",
    "                             'max_depth': [n for n in range(0,50,5)],\n",
    "                             'n_estimators': [n for n in range(0,1000,10)],\n",
    "                             'subsample': np.arange(0.3, 1,0.1),\n",
    "                             'loss': ['deviance'],\n",
    "                             'warm_start': [True, False],\n",
    "                             'presort': ['auto'],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   17.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                        criterion='friedman_mse',\n",
       "                                                        init=None,\n",
       "                                                        learning_rate=0.1,\n",
       "                                                        loss='deviance',\n",
       "                                                        max_depth=3,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        n_estimators=100,\n",
       "                                                        n_ite...\n",
       "                                        'min_weight_fraction_leaf': array([0.]),\n",
       "                                        'n_estimators': [0, 10, 20, 30, 40, 50,\n",
       "                                                         60, 70, 80, 90, 100,\n",
       "                                                         110, 120, 130, 140,\n",
       "                                                         150, 160, 170, 180,\n",
       "                                                         190, 200, 210, 220,\n",
       "                                                         230, 240, 250, 260,\n",
       "                                                         270, 280, 290, ...],\n",
       "                                        'presort': ['auto'],\n",
       "                                        'subsample': array([0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                        'warm_start': [True, False]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = GBC()\n",
    "rf_GBC = RandomizedSearchCV(estimator = rf, param_distributions = params_GBC, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_GBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.25000000000000006,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 35,\n",
       " 'max_features': 52,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'min_samples_split': 0.1,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 190,\n",
       " 'presort': 'auto',\n",
       " 'subsample': 0.8000000000000003,\n",
       " 'warm_start': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_GBC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 72.00%.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-ac736983bac4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-ac736983bac4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    random_accuracy = evaluate(best_GBC, X_test), y_test)\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "best_GBC = rf_GBC.best_estimator_\n",
    "random_accuracy = evaluate(best_GBC, X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction_accuracy(best_GBC, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb #conda install -c conda-forge xgboost \n",
    "\n",
    "params_XGB = {\n",
    "                              'objective': ['binary:logistic'],'learning_rate':np.arange(0.1,0.5,0.1),\n",
    "                              'n_estimators':np.arange(16,116,15),\n",
    "                              'scale_pos_weight':np.arange(2,6,1),\n",
    "                              'max_depth':np.arange(4,12,1),'min_child_weight':np.arange(1,10,1),\n",
    "                              'gamma':np.arange(0,0.5,0.1),\n",
    "                              'subsample':np.arange(0.6,1,0.1),'colsample_bytree':np.arange(0.6,0.91,0.05),\n",
    "                              'colsample_bylevel':np.arange(0.6,0.91,0.05)#,\n",
    "                             # {'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]} # Empeoraba muchísimo con esto, y Luis dijo que no importaba\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = xgb.XGBClassifier()\n",
    "rf_XGB = RandomizedSearchCV(estimator = rf, param_distributions = params_XGB, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_XGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train.drop(columns='id'), y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction_accuracy(best_XGB, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICCIONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
