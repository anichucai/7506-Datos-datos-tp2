{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk, os, re, string, collections\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from  imageio import imread\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import multidict as multidict #pip install multidict\n",
    "import itertools\n",
    "#import csvtomd\n",
    "import re\n",
    "from collections import Counter\n",
    "#%matplotlib inline\n",
    "import spacy\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, Binarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('original_data/train.csv')\n",
    "test  = pd.read_csv('original_data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253\n"
     ]
    }
   ],
   "source": [
    "def getStopwordsList():\n",
    "    fileNamesList = [\"texts/99webtools.txt\", \"texts/atire_ncbi.txt\", \"texts/atire_puurula.txt\", \"texts/azure.txt\", \n",
    "                 \"texts/bbalet.txt\", \n",
    "                 \"texts/bow_short.txt\", \"texts/choi_2000naacl.txt\", \"texts/cook1988_function_words.txt\", \n",
    "                 \"texts/corenlp_acronym.txt\", \n",
    "                 \"texts/corenlp_hardcoded.txt\", \"texts/corenlp_stopwords.txt\", \"texts/datasciencedojo.txt\", \n",
    "                 \"texts/deeplearning4j.txt\", \n",
    "                 \"texts/dkpro.txt\", \"texts/mongodb.txt\", \"texts/galago_inquery.txt\", \"texts/gate_keyphrase.txt\", \n",
    "                 \"texts/gensim.txt\", \n",
    "                 \"texts/glasgow_stop_words.txt\", \"texts/indri.txt\", \"texts/kevinbouge.txt\", \"texts/lexisnexis.txt\",\n",
    "                 \"texts/lingpipe.txt\", \n",
    "                 \"texts/mallet.txt\", \"texts/mysql_innodb.txt\", \"texts/mysql_myisam.txt\", \"texts/galago_rmstop.txt\", \n",
    "                 \"texts/atire_ncbi.txt\", \n",
    "                 \"texts/galago_rmstop.txt\", \"texts/nltk.txt\", \"texts/okapiframework.txt\", \"texts/okapi_cacm_expanded.txt\", \n",
    "                 \"texts/onix.txt\", \n",
    "                 \"texts/ovid.txt\", \"texts/postgresql.txt\", \"texts/pubmed.txt\", \"texts/quanteda.txt\", \"texts/r_tm.txt\", \n",
    "                 \"texts/ranksnl_large.txt\", \n",
    "                 \"texts/reuters_wos.txt\", \"texts/rouge_155.txt\", \"texts/scikitlearn.txt\", \"texts/smart.txt\", \n",
    "                 \"texts/snowball_expanded.txt\", \n",
    "                 \"texts/spacy.txt\", \"texts/spark_mllib.txt\", \"texts/sphinx_mirasvit.txt\", \"texts/t101_minimal.txt\", \n",
    "                 \"texts/taporware.txt\", \n",
    "                 \"texts/terrier.txt\", \"texts/tonybsk_1.txt\", \"texts/tonybsk_6.txt\", \"texts/voyant_taporware.txt\", \n",
    "                 \"texts/weka.txt\", \n",
    "                 \"texts/xapian.txt\", \"texts/xpo6.txt\", \"texts/zettair.txt\"]\n",
    "    stopwordsList = []\n",
    "    for fileName in fileNamesList:\n",
    "        file = open(fileName, \"r\", encoding=\"utf8\")\n",
    "        for line in file:\n",
    "            stripped_line = line. strip()\n",
    "            line_list = stripped_line\n",
    "            if line_list not in stopwordsList:\n",
    "                stopwordsList.append(line_list)\n",
    "        file.close()\n",
    "    return stopwordsList\n",
    "\n",
    "stopwordsList = getStopwordsList()\n",
    "\n",
    "print(len(stopwordsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_strict(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\d+', '')\n",
    "    invalid_chars = ['#','|','@','!','?','-','_','[',']','%','&',':','.',',',\"''\",'/','https','(','//t',')','http',\n",
    "                 ';','\\'']\n",
    "    for char in invalid_chars:\n",
    "        if char in text:\n",
    "            text = text.replace(char,' ')\n",
    "    #removes url and tags\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \" \",  text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES AUXILIARES\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def prettify(word):\n",
    "    word = re.sub(r'[^A-Za-z]', \" \",  word)\n",
    "    word = re.sub(r'\\b\\w\\b',' ', word)\n",
    "    word = re.sub(r'\\s+', ' ', word)\n",
    "    return word\n",
    "\n",
    "def cleanStopwords(tweet):\n",
    "    tweet = tweet.split(' ')\n",
    "    cleanTweet=\"\"\n",
    "    for word in tweet:\n",
    "        if word not in stopwordsList:\n",
    "            cleanTweet = cleanTweet + \" \" + word\n",
    "    return cleanTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text = train[\"text\"].apply(lambda x: clean_text_strict(x))\n",
    "test.text = test[\"text\"].apply(lambda x: clean_text_strict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       our deeds are the reason of this  earthquake m...\n",
       "1                  forest fire near la ronge sask  canada\n",
       "2       all residents asked to  shelter in place  are ...\n",
       "3       13 000 people receive  wildfires evacuation or...\n",
       "4       just got sent this photo from ruby  alaska as ...\n",
       "                              ...                        \n",
       "7608    two giant cranes holding a bridge collapse int...\n",
       "7609     aria ahrary  thetawniest the out of control w...\n",
       "7610    m1 94  01 04 utc  5km s of volcano hawaii     ...\n",
       "7611    police investigating after an e bike collided ...\n",
       "7612    the latest  more homes razed by northern calif...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text = train.text.apply(prettify)\n",
    "test.text = test.text.apply(prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       our deeds are the reason of this earthquake ma...\n",
       "1                   forest fire near la ronge sask canada\n",
       "2       all residents asked to shelter in place are be...\n",
       "3        people receive wildfires evacuation orders in...\n",
       "4       just got sent this photo from ruby alaska as s...\n",
       "                              ...                        \n",
       "7608    two giant cranes holding bridge collapse into ...\n",
       "7609     aria ahrary thetawniest the out of control wi...\n",
       "7610               utc km of volcano hawaii co zdtoyd ebj\n",
       "7611    police investigating after an bike collided wi...\n",
       "7612    the latest more homes razed by northern califo...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "def lemmatize_text_v2(text):\n",
    "    if text == '' or pd.isnull(text):\n",
    "        return text\n",
    "    else:\n",
    "        doc = nlp(text)\n",
    "        return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "train.text = train.text.apply(lemmatize_text_v2)\n",
    "test.text  = test.text.apply(lemmatize_text_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -PRON- deed be the reason of this earthquake m...\n",
       "1                   forest fire near la ronge sask canada\n",
       "2       all resident ask to shelter in place be be not...\n",
       "3         people receive wildfire evacuation order in ...\n",
       "4       just get send this photo from ruby alaska as s...\n",
       "                              ...                        \n",
       "7608    two giant crane hold bridge collapse into near...\n",
       "7609      aria ahrary thetawniest the out of control w...\n",
       "7610               utc km of volcano hawaii co zdtoyd ebj\n",
       "7611    police investigate after an bike collide with ...\n",
       "7612    the late more home raze by northern california...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text = train.text.apply(cleanStopwords)\n",
    "test.text  = test.text.apply(cleanStopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          terrible crash\n",
       "1                                    earthquake city safe\n",
       "2          forest fire spot pond goose flee street -PRON-\n",
       "3                    apocalypse lighting spokane wildfire\n",
       "4                      typhoon soudelor kill china taiwan\n",
       "                              ...                        \n",
       "3258     earthquake safety los angeles safety fastener...\n",
       "3259     storm ri hurricane -PRON- city hit -PRON- yar...\n",
       "3260                  green derailment chicago utbxlcbiuy\n",
       "3261                     meg hazardous outlook hwo rbqjhn\n",
       "3262       cityofcalgary activate -PRON- municipal eme...\n",
       "Name: text, Length: 3263, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorización de Texto para modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaallll</th>\n",
       "      <th>aaaaaand</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aace</th>\n",
       "      <th>aag</th>\n",
       "      <th>aal</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aan</th>\n",
       "      <th>...</th>\n",
       "      <th>zzcupnz</th>\n",
       "      <th>zzk</th>\n",
       "      <th>zznbvfuvo</th>\n",
       "      <th>zzpojgngaj</th>\n",
       "      <th>zzr</th>\n",
       "      <th>zzsee</th>\n",
       "      <th>zztbvjypn</th>\n",
       "      <th>zzuz</th>\n",
       "      <th>zzweeezjug</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 19203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaaa  aaaaaaallll  aaaaaand  aaarrrgghhh  aace  aag  aal  aamir  \\\n",
       "id                                                                           \n",
       "0       0     0            0         0            0     0    0    0      0   \n",
       "2       0     0            0         0            0     0    0    0      0   \n",
       "3       0     0            0         0            0     0    0    0      0   \n",
       "9       0     0            0         0            0     0    0    0      0   \n",
       "11      0     0            0         0            0     0    0    0      0   \n",
       "...    ..   ...          ...       ...          ...   ...  ...  ...    ...   \n",
       "10861   0     0            0         0            0     0    0    0      0   \n",
       "10865   0     0            0         0            0     0    0    0      0   \n",
       "10868   0     0            0         0            0     0    0    0      0   \n",
       "10874   0     0            0         0            0     0    0    0      0   \n",
       "10875   0     0            0         0            0     0    0    0      0   \n",
       "\n",
       "       aan  ...  zzcupnz  zzk  zznbvfuvo  zzpojgngaj  zzr  zzsee  zztbvjypn  \\\n",
       "id          ...                                                               \n",
       "0        0  ...        0    0          0           0    0      0          0   \n",
       "2        0  ...        0    0          0           0    0      0          0   \n",
       "3        0  ...        0    0          0           0    0      0          0   \n",
       "9        0  ...        0    0          0           0    0      0          0   \n",
       "11       0  ...        0    0          0           0    0      0          0   \n",
       "...    ...  ...      ...  ...        ...         ...  ...    ...        ...   \n",
       "10861    0  ...        0    0          0           0    0      0          0   \n",
       "10865    0  ...        0    0          0           0    0      0          0   \n",
       "10868    0  ...        0    0          0           0    0      0          0   \n",
       "10874    0  ...        0    0          0           0    0      0          0   \n",
       "10875    0  ...        0    0          0           0    0      0          0   \n",
       "\n",
       "       zzuz  zzweeezjug  zzzz  \n",
       "id                             \n",
       "0         0           0     0  \n",
       "2         0           0     0  \n",
       "3         0           0     0  \n",
       "9         0           0     0  \n",
       "11        0           0     0  \n",
       "...     ...         ...   ...  \n",
       "10861     0           0     0  \n",
       "10865     0           0     0  \n",
       "10868     0           0     0  \n",
       "10874     0           0     0  \n",
       "10875     0           0     0  \n",
       "\n",
       "[3263 rows x 19203 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAG OF WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer=CountVectorizer(analyzer='word',binary=True)\n",
    "count_vectorizer.fit(train.text)\n",
    "\n",
    "train_vec = count_vectorizer.fit_transform(train.text)\n",
    "test_vec = count_vectorizer.transform(test.text)\n",
    "\n",
    "train_vec = pd.DataFrame(train_vec.toarray(),columns=count_vectorizer.get_feature_names())\n",
    "train_vec.set_index(train.id)\n",
    "\n",
    "test_vec = pd.DataFrame(test_vec.toarray(),columns=count_vectorizer.get_feature_names())\n",
    "test_vec.set_index(test.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF -> BAJA SCORE\n",
    "\n",
    "#tf_idf = TfidfVectorizer(use_idf=True, \n",
    "#                        smooth_idf=True,  \n",
    "#                        ngram_range=(1,1),stop_words='english')\n",
    "\n",
    "#train_vec = tf_idf.fit_transform(train.text)\n",
    "#test_vec  = tf_idf.transform(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_accuracy(modelo,x_train,y_train,x_test,y_test):\n",
    "    with open(\"prediction_history.csv\", \"a\") as myfile:\n",
    "        predicted = modelo.predict(x_train)\n",
    "        train_prediction = str(metrics.accuracy_score(y_train,predicted))\n",
    "        print('Score para x_train: '+ train_prediction)\n",
    "        predicted = modelo.predict(x_test)\n",
    "        test_prediction = str(metrics.accuracy_score(y_test,predicted))\n",
    "        print('Score para x_test: '+ test_prediction)\n",
    "        params = str(modelo)\n",
    "        print('Hiperparametros: '+ str(modelo))\n",
    "        myfile.write(params+','+test_prediction+\",\"+train_prediction+\",\"+str(datetime.datetime.now())+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(model, test, name):\n",
    "    predicted = model.predict(test)\n",
    "    sample_submission.target = predicted\n",
    "    df_prediccion.to_csv('predictions/'+name+str(datetime.datetime.now())+'.csv', index=None)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('original_data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_vec,y,test_size=0.2,random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación sobre algunos modelos básicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(model,X_train,y_train,X_test,y_test):    \n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions=clf.predict(X_test)\n",
    "    confusion_matrix(y_test,predictions)\n",
    "    conf = metrics.confusion_matrix(y_test, predictions)\n",
    "    conf = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]\n",
    "    print_cm(conf, ['true','false'])\n",
    "    print('-'*50)\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print('-'*50)\n",
    "    print(\"{}\" .format(model))\n",
    "    print('-'*50)\n",
    "    print('Accuracy of classifier on training set:{}%'.format(round(clf.score(X_train, y_train)*100)))\n",
    "    print('-'*50)\n",
    "    print('Accuracy of classifier on test set:{}%' .format(round(accuracy_score(y_test,predictions)*100)))\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[LogisticRegression(C=1.0, max_iter=1000),SVC(),MultinomialNB(),DecisionTreeClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors=5),RandomForestClassifier(),GaussianNB(),SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           true false \n",
      "     true   0.9   0.1 \n",
      "    false   0.3   0.7 \n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       849\n",
      "           1       0.85      0.72      0.78       674\n",
      "\n",
      "    accuracy                           0.82      1523\n",
      "   macro avg       0.82      0.81      0.81      1523\n",
      "weighted avg       0.82      0.82      0.82      1523\n",
      "\n",
      "--------------------------------------------------\n",
      "LogisticRegression(max_iter=1000)\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on training set:96%\n",
      "--------------------------------------------------\n",
      "Accuracy of classifier on test set:82%\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    fit_and_predict(model,X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multibinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaallll</th>\n",
       "      <th>aaaaaand</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aace</th>\n",
       "      <th>aag</th>\n",
       "      <th>aal</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aan</th>\n",
       "      <th>...</th>\n",
       "      <th>zzcupnz</th>\n",
       "      <th>zzk</th>\n",
       "      <th>zznbvfuvo</th>\n",
       "      <th>zzpojgngaj</th>\n",
       "      <th>zzr</th>\n",
       "      <th>zzsee</th>\n",
       "      <th>zztbvjypn</th>\n",
       "      <th>zzuz</th>\n",
       "      <th>zzweeezjug</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 19203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaaa  aaaaaaallll  aaaaaand  aaarrrgghhh  aace  aag  aal  aamir  \\\n",
       "0      0     0            0         0            0     0    0    0      0   \n",
       "1      0     0            0         0            0     0    0    0      0   \n",
       "2      0     0            0         0            0     0    0    0      0   \n",
       "3      0     0            0         0            0     0    0    0      0   \n",
       "4      0     0            0         0            0     0    0    0      0   \n",
       "...   ..   ...          ...       ...          ...   ...  ...  ...    ...   \n",
       "7608   0     0            0         0            0     0    0    0      0   \n",
       "7609   0     0            0         0            0     0    0    0      0   \n",
       "7610   0     0            0         0            0     0    0    0      0   \n",
       "7611   0     0            0         0            0     0    0    0      0   \n",
       "7612   0     0            0         0            0     0    0    0      0   \n",
       "\n",
       "      aan  ...  zzcupnz  zzk  zznbvfuvo  zzpojgngaj  zzr  zzsee  zztbvjypn  \\\n",
       "0       0  ...        0    0          0           0    0      0          0   \n",
       "1       0  ...        0    0          0           0    0      0          0   \n",
       "2       0  ...        0    0          0           0    0      0          0   \n",
       "3       0  ...        0    0          0           0    0      0          0   \n",
       "4       0  ...        0    0          0           0    0      0          0   \n",
       "...   ...  ...      ...  ...        ...         ...  ...    ...        ...   \n",
       "7608    0  ...        0    0          0           0    0      0          0   \n",
       "7609    0  ...        0    0          0           0    0      0          0   \n",
       "7610    0  ...        0    0          0           0    0      0          0   \n",
       "7611    0  ...        0    0          0           0    0      0          0   \n",
       "7612    0  ...        0    0          0           0    0      0          0   \n",
       "\n",
       "      zzuz  zzweeezjug  zzzz  \n",
       "0        0           0     0  \n",
       "1        0           0     0  \n",
       "2        0           0     0  \n",
       "3        0           0     0  \n",
       "4        0           0     0  \n",
       "...    ...         ...   ...  \n",
       "7608     0           0     0  \n",
       "7609     0           0     0  \n",
       "7610     0           0     0  \n",
       "7611     0           0     0  \n",
       "7612     0           0     0  \n",
       "\n",
       "[7613 rows x 19203 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 91.00%.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy = round(accuracy_score(y_test,predictions)*100)\n",
    "print('Model Performance')\n",
    "print('Accuracy = {:0.2f}%.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para x_train: 0.9254515599343186\n",
      "Score para x_test: 0.9146421536441235\n",
      "Hiperparametros: MultinomialNB(alpha=1)\n"
     ]
    }
   ],
   "source": [
    "save_prediction_accuracy(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=1.0, max_iter=1000)\n",
    "model.fit(train_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 96.00%.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy = round(accuracy_score(y_test,predictions)*100)\n",
    "print('Model Performance')\n",
    "print('Accuracy = {:0.2f}%.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_prediction_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c9ef687204c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_prediction_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_prediction_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "save_prediction_accuracy(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT ON TEST AND SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction(model, test_vec, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
